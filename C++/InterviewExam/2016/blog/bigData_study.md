# 大数据算法总结

#### 梯度下降法
梯度下降，主要用于回归拟合过程中，寻找最优解或局部最优解。梯度下降法是因为在拟合过程中，调整参数alpha，使得
误差函数值沿着梯度下降的方向变化而得名。误差函数Re(alpha) = 估计函数 - 真实值。

估计函数就是需要拟合的模型，这是一个不断拟合逼近的过程，不断的修改参数alpha向量，得到误差最小的估计函数模型。

回归拟合过程成，求最小误差方法有，最小二乘法(矩阵的奇异值，QR分解，求解本身无解的方程Ax=b，得到最优解)，梯度下降法

回归：给一个数据点集，用一条曲线去拟合这些点集，使得曲线尽可能准确的描叙点集特征。如果曲线是直线，则为线性回归；
二次曲线，则为二次回归，...回归。

#### K-近邻算法
所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（k个邻居）， 
这K个实例的多数属于某个类，就把该输入实例分类到这个类中。

选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。

#### k-means算法
k-means 算法接受输入量 k ；然后将n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；
而不同聚类中的对象相似度较小。聚类相似度是利用各聚类中对象的均值所获得一个“中心对象”（引力中心）来进行计算的。

	1.从 n个数据对象任意选择 k 个对象作为初始聚类中心；
	2.根据每个聚类对象的均值（中心对象），计算每个对象与这些中心对象的距离；并根据最小距离重新对相应对象进行划分；
	3.重新计算每个（有变化）聚类的均值（中心对象）；
	4.计算标准测度函数，当满足一定条件，如函数收敛时，则算法终止；如果条件不满足则回到步骤（2）。